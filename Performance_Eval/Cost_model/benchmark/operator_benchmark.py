import zmq
import pickle
import torch
import operator
import time
import sys
import traceback
import gc
from typing import Any, Tuple, Dict, Optional, Callable
from functools import lru_cache

# å°è¯•å¯¼å…¥ NPU æ”¯æŒ
try:
    import torch_npu
except ImportError:
    pass

# ==============================================================================
# 1. è®¾å¤‡ä¸Šä¸‹æ–‡ç®¡ç† (Device Context Abstraction)
# ==============================================================================
class DeviceContext:
    """
    å°è£…è®¾å¤‡ç‰¹å®šçš„æ“ä½œï¼ˆåŒæ­¥ã€è®¡æ—¶äº‹ä»¶ã€æ¸…ç©ºç¼“å­˜ï¼‰ï¼Œ
    é¿å…åœ¨ä¸»å¾ªç¯ä¸­é‡å¤è¿›è¡Œ if-else æ£€æµ‹ã€‚
    """
    def __init__(self):
        self.device_type = 'cpu'
        self.device_str = 'cpu'
        self.event_cls = None
        self._sync_func = lambda: None
        self._empty_cache_func = lambda: None

        if hasattr(torch, 'npu') and torch.npu.is_available():
            self.device_type = 'npu'
            self.device_str = 'npu:0'
            self.event_cls = torch.npu.Event
            self._sync_func = torch.npu.synchronize
            self._empty_cache_func = torch.npu.empty_cache
            # print(f"âœ… [DeviceContext] Activated: NPU ({torch.npu.get_device_name(0)})")
        elif torch.cuda.is_available():
            self.device_type = 'cuda'
            self.device_str = 'cuda:0'
            self.event_cls = torch.cuda.Event
            self._sync_func = torch.cuda.synchronize
            self._empty_cache_func = torch.cuda.empty_cache
            # print(f"âœ… [DeviceContext] Activated: CUDA ({torch.cuda.get_device_name(0)})")
        else:
            pass
            # print(f"âš ï¸ [DeviceContext] Activated: CPU only")

    def synchronize(self):
        self._sync_func()

    def empty_cache(self):
        self._empty_cache_func()

    def create_tensor(self, shape, dtype) -> torch.Tensor:
        # ä½¿ç”¨ ones é¿å…é™¤é›¶é”™è¯¯ï¼Œä¸è®¡ç®—æ¢¯åº¦ä»¥èŠ‚çœæ˜¾å­˜
        return torch.ones(shape, dtype=dtype, device=self.device_str).requires_grad_(False)

    def get_timer_events(self):
        if self.event_cls:
            return self.event_cls(enable_timing=True), self.event_cls(enable_timing=True)
        return None, None

# å…¨å±€å•ä¾‹
CTX = DeviceContext()

# ==============================================================================
# 2. æ ¸å¿ƒ Benchmark ç±»
# ==============================================================================
class OperatorBenchmark:
    """
    å¯¹å•ä¸€ Torch FX èŠ‚ç‚¹æ‰§è¡Œç®—å­åŸºå‡†æµ‹è¯•ã€‚
    """
    WARMUP_ITERS = 5
    RUN_ITERS = 20
    IGNORED_KWARGS = {"layer_Rank", "Stage", "sharding_spec"} # æ‰©å……å¸¸è§çš„ä¸éœ€è¦çš„å‚æ•°

    def __init__(self, verbose: bool = True):
        self.verbose = verbose

    @lru_cache(maxsize=1024)
    def _resolve_target(self, target_name: str) -> Optional[Callable]:
        """
        è§£æç®—å­ç›®æ ‡ï¼Œå¢åŠ ç¼“å­˜ä»¥æå‡é‡å¤ç®—å­çš„å¤„ç†é€Ÿåº¦ã€‚
        """
        if hasattr(operator, target_name):
            return getattr(operator, target_name)
        if hasattr(torch, target_name):
            return getattr(torch, target_name)
        
        # å¤æ‚è·¯å¾„è§£æ (e.g. torch.ops.aten.add.Tensor)
        if "." in target_name:
            parts = target_name.split(".")
            obj = torch
            try:
                for part in parts:
                    if part == 'torch': continue
                    obj = getattr(obj, part)
                return obj
            except AttributeError:
                pass
            
            # å°è¯• aten ops
            if len(parts) >= 2:
                op_name, op_variant = parts[0], parts[1]
                if hasattr(torch.ops.aten, op_name):
                    aten_op = getattr(torch.ops.aten, op_name)
                    if hasattr(aten_op, op_variant):
                        return getattr(aten_op, op_variant)
        return None

    def _format_arg_summary(self, args, kwargs) -> str:
            if not self.verbose: return ""

            def simple_fmt(x):
                # 1.å¦‚æœæ˜¯ Tensorï¼Œæ‰“å° Shape å’Œ Dtype
                if isinstance(x, torch.Tensor):
                    shape_str = str(list(x.shape))
                    dtype_str = str(x.dtype).replace('torch.', '')
                    return f"Tensor({shape_str}, {dtype_str})"
                
                # 2. ã€å…³é”®ä¿®æ”¹ã€‘å¦‚æœæ˜¯åˆ—è¡¨æˆ–å…ƒç»„ï¼Œé€’å½’æ‰“å°å†…éƒ¨å†…å®¹
                elif isinstance(x, (list, tuple)):
                    inner = ", ".join([simple_fmt(item) for item in x])
                    return f"[{inner}]"
                
                # 3.å¦‚æœæ˜¯åŸºç¡€ç±»å‹ï¼Œç›´æ¥æ˜¾ç¤ºå€¼
                elif isinstance(x, (int, float, str, bool)):
                    return str(x)
                    
                # 4.å…¶ä»–æƒ…å†µæ‰“å°ç±»å‹å
                return str(type(x).__name__)
            
            arg_str = ", ".join([simple_fmt(a) for a in args])
            
            # å¦‚æœ kwargs ä¹Ÿæœ‰å†…å®¹ï¼Œé¡ºä¾¿æ‰“å°å‡ºæ¥
            if kwargs:
                kwarg_str = ", ".join([f"{k}={simple_fmt(v)}" for k, v in kwargs.items()])
                return f"Args: {arg_str} | Kwargs: {kwarg_str}"
                
            return f"Args: {arg_str}"

    def benchmark(self, node: Any, dummy_args: Tuple[Any, ...], dummy_kwargs: Dict[str, Any]) -> Tuple[bool, float]:
        target_str = str(node.target)
        try:
            # 1. è§£æå‡½æ•°
            op_func = self._resolve_target(target_str)
            filtered_kwargs = {k: v for k, v in dummy_kwargs.items() if k not in self.IGNORED_KWARGS}

            func_to_run = None
            run_args = dummy_args
            run_kwargs = filtered_kwargs
            real_op_name = target_str

            # 2. ç¡®å®šè°ƒç”¨æ–¹å¼ (Function vs Method)
            if op_func is not None:
                real_op_name = getattr(op_func, "__name__", target_str)
                func_to_run = op_func
            elif node.op == "call_method":
                method_name = target_str
                obj = dummy_args[0]
                if not hasattr(obj, method_name):
                    raise RuntimeError(f"Object {type(obj)} has no method: {method_name}")
                func_to_run = getattr(obj, method_name)
                run_args = dummy_args[1:] # self æ˜¯ objï¼Œä» args ç§»é™¤
                real_op_name = f"Tensor.{method_name}"
            else:
                raise RuntimeError(f"Unresolvable target: {target_str}")

            if self.verbose:
                print("-" * 60)
                print(f"[Run] Node: {node.name} | Op: {real_op_name}")
                print(f"[Run] {self._format_arg_summary(dummy_args, dummy_kwargs)}")

            # 3. æ‰§è¡Œè®¡æ—¶
            CTX.synchronize() # é¢„åŒæ­¥ï¼Œç¡®ä¿ä¹‹å‰çš„æ“ä½œå®Œæˆ

            # Warmup
            for _ in range(self.WARMUP_ITERS):
                func_to_run(*run_args, **run_kwargs)
            
            CTX.synchronize() # Warmup ç»“æŸåŒæ­¥

            # Timing Run
            start_event, end_event = CTX.get_timer_events()
            
            if start_event:
                # GPU/NPU è®¡æ—¶è·¯å¾„
                start_event.record()
                for _ in range(self.RUN_ITERS):
                    func_to_run(*run_args, **run_kwargs)
                end_event.record()
                CTX.synchronize() # ç­‰å¾… Event è®°å½•å®Œæˆ
                total_ms = start_event.elapsed_time(end_event)
                mean_time_sec = (total_ms / self.RUN_ITERS) / 1000.0
            else:
                # CPU è®¡æ—¶è·¯å¾„
                start_t = time.perf_counter()
                for _ in range(self.RUN_ITERS):
                    func_to_run(*run_args, **run_kwargs)
                end_t = time.perf_counter()
                mean_time_sec = (end_t - start_t) / self.RUN_ITERS

            if self.verbose:
                print(f"[Result] {mean_time_sec * 1e6:.2f} us")

            return True, mean_time_sec

        except Exception as e:
            if self.verbose:
                pass
                # print(f"âŒ [Exec Error] {node.name}: {str(e)}")
                # traceback.print_exc() # å¯é€‰ï¼šæ‰“å°è¯¦ç»†å †æ ˆ
            return False, 0.0
        finally:
            # è¿™é‡Œçš„ finally å¹¶ä¸ä¸€å®šéœ€è¦ empty_cacheï¼Œé¢‘ç¹è°ƒç”¨ä¼šæ…¢ã€‚
            # æ”¾åœ¨ Server å¾ªç¯æœ«å°¾è°ƒç”¨æ¯”è¾ƒå¥½ã€‚
            pass

# ==============================================================================
# 3. æ•°æ®è¿˜åŸé€»è¾‘ (Helper)
# ==============================================================================
class DataReconstructor:
    @staticmethod
    def _str_to_dtype(dtype_str: str):
        # ç§»é™¤å¯èƒ½çš„å‰ç¼€
        clean_str = dtype_str.replace('torch.', '')
        if hasattr(torch, clean_str):
            return getattr(torch, clean_str)
        raise ValueError(f"Unknown dtype string: {dtype_str}")

    @classmethod
    def reconstruct(cls, arg):
        if isinstance(arg, (list, tuple)):
            return type(arg)(cls.reconstruct(x) for x in arg)
        elif isinstance(arg, dict):
            # æ£€æµ‹æ˜¯å¦ä¸º Tensor Metadata
            if 'shape' in arg and 'dtype' in arg:
                try:
                    dtype = cls._str_to_dtype(arg['dtype'])
                    return CTX.create_tensor(arg['shape'], dtype)
                except Exception as e:
                    pass
                    # print(f"\nâŒ [Data Error] Failed to create tensor: {arg}")
                    # raise e
            return {k: cls.reconstruct(v) for k, v in arg.items()}
        else:
            return arg

# ==============================================================================
# 4. Mock Node (ä¿æŒä¸å˜)
# ==============================================================================
class MockNode:
    def __init__(self, target_str, name_str, op_type='call_function'):
        self.target = target_str 
        self.name = name_str
        self.op = op_type

# ==============================================================================
# 5. Server é€šä¿¡é€»è¾‘
# ==============================================================================
class BenchmarkServer:
    def __init__(self, port=5588):
        self.context = zmq.Context()
        self.socket = self.context.socket(zmq.REP)
        # è®¾ç½® Linger ä¸º 0ï¼Œé˜²æ­¢ Ctrl+C æ—¶ socket å¡æ­»
        self.socket.setsockopt(zmq.LINGER, 0)
        self.socket.bind(f"tcp://*:{port}")
        
        self.benchmarker = OperatorBenchmark(verbose=True)
        print(f"ğŸš€ Benchmark Server Running on {CTX.device_type.upper()} | Port: {port}")

    def start(self):
        print(">> Waiting for requests...")
        while True:
            try:
                # 1. æ¥æ”¶
                msg = self.socket.recv()
                payload = pickle.loads(msg)
                
                op_name = payload.get('op', 'unknown')
                node_name = payload.get('name', 'remote_node')
                
                # 2. æ„é€  Node å’Œå‚æ•°
                mock_node = MockNode(op_name, node_name, op_type='call_function')
                
                # ä½¿ç”¨ä¸“é—¨çš„é‡æ„å™¨ï¼Œè‹¥å‡ºé”™ä¼šæŠ›å‡ºå¼‚å¸¸ä¸­æ–­æœ¬æ¬¡æµ‹è¯•ï¼Œä½†è¢« except æ•è·
                real_args = DataReconstructor.reconstruct(payload['args'])
                real_kwargs = DataReconstructor.reconstruct(payload['kwargs'])

                # 3. æ‰§è¡Œ
                success, cost_time = self.benchmarker.benchmark(
                    mock_node, 
                    tuple(real_args), 
                    real_kwargs
                )

                # 4. å›å¤
                resp = pickle.dumps({'success': success, 'time': cost_time})
                self.socket.send(resp)

            except Exception as e:
                pass
                # print(f"âŒ [Server Loop Error] {e}")
                # traceback.print_exc()
                
                # å…³é”®ï¼šç¡®ä¿ Send è¢«è°ƒç”¨ï¼Œå¦åˆ™ Client ä¼šä¸€ç›´ç­‰å¾… recv å¯¼è‡´æ­»é”
                try:
                    err_resp = pickle.dumps({'success': False, 'time': 0.0, 'error': str(e)})
                    self.socket.send(err_resp)
                except zmq.ZMQError:
                    # å¦‚æœ send ä¹Ÿå¤±è´¥ï¼ˆæ¯”å¦‚ socket çŠ¶æ€é”™è¯¯ï¼‰ï¼Œé€šå¸¸éœ€è¦é‡ç½® socket
                    print("âš ï¸ Critical ZMQ Error during error reporting.")
            
            finally:
                # 5. æ¸…ç† (é˜²æ­¢ OOM)
                # æ¯æ¬¡è¯·æ±‚åç®€å•æ¸…ç†å¼•ç”¨
                del msg, payload
                if 'real_args' in locals(): del real_args
                if 'real_kwargs' in locals(): del real_kwargs
                
                # NPU/CUDA æ˜¾å­˜æ¸…ç†ï¼š
                # é¢‘ç¹ empty_cache ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ï¼Œä½† Benchmark åœºæ™¯ä¸‹ç¨³å®šæ€§ä¼˜å…ˆ
                # å¦‚æœå‘ç°å¤ªæ…¢ï¼Œå¯ä»¥åŠ è®¡æ•°å™¨ï¼Œæ¯ 10 æ¬¡è¯·æ±‚æ¸…ç†ä¸€æ¬¡
                # CTX.empty_cache() 
                pass

if __name__ == "__main__":
    # è®¾ç½® Python åƒåœ¾å›æ”¶é˜ˆå€¼ï¼Œç¨å¾®æ¿€è¿›ä¸€ç‚¹é˜²æ­¢ Tensor æ³„éœ²
    gc.set_threshold(700, 10, 10)
    
    try:
        server = BenchmarkServer()
        server.start()
    except KeyboardInterrupt:
        print("\nğŸ›‘ Server shutting down...")
    except Exception as e:
        print(f"ğŸ›‘ Fatal Error: {e}")